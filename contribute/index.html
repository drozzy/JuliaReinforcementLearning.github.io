<!doctype html> <html lang=en > <script async src="https://www.googletagmanager.com/gtag/js?id=UA-149861753-1"></script> <script> window.dataLayer = window.dataLayer || []; function gtag() { dataLayer.push(arguments); } gtag('js', new Date()); gtag('config', 'UA-149861753-1'); </script> <meta charset=utf-8 > <meta name=viewport  content="width=device-width, initial-scale=1, shrink-to-fit=no"> <link rel=icon  href="/assets/site/logo.svg"> <title>Call for Contributions</title> <link rel=stylesheet  href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/css/bootstrap.min.css" integrity="sha384-9aIt2nRpC12Uk9gS9baDl411NQApFmC26EwAOH8WgZl5MYYxFfc+NcPb1dKGj7Sk" crossorigin=anonymous > <link href="/css/custom.css" rel=stylesheet > <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin=anonymous ></script> <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin=anonymous ></script> <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/js/bootstrap.min.js" integrity="sha384-OgVRvuATP1z7JjHLkuOU7Xw704+h835Lr+6QL9UvYjZE3Ipu6Tp75j7Bh/kR0JKI" crossorigin=anonymous ></script> <script src="/libs/distill/template.v2.8.0.js"></script> <d-front-matter> <script id=distill-front-matter  type="text/json"> { "authors": [ { "author":"Jun Tian", "authorURL":"https://github.com/findmyway", "affiliation":"", "affiliationURL":"" } ], "publishedDate":"2021-02-22T02:35:59.381", "citationText":"Jun Tian, 2021" } </script> </d-front-matter> <nav class="navbar navbar-expand-lg navbar-dark fixed-top" style="background-color: #1fd1f9; background-image: linear-gradient(315deg, #1fd1f9 0%, #b621fe 74%); " id=mainNav > <div class=container > <button class=navbar-toggler  type=button  data-toggle=collapse  data-target="#navbarTogglerDemo01" aria-controls=navbarTogglerDemo01  aria-expanded=false  aria-label="Toggle navigation"> <span class=navbar-toggler-icon ></span> </button> <div class="collapse navbar-collapse" id=navbarTogglerDemo01 > <span class=navbar-brand > <a class=navbar-brand  href="/"> JuliaReinforcementLearning </a> </span> <ul class="navbar-nav ml-auto"> <li class=nav-item > <a class=nav-link  href="/get_started/">Get Started</a> <li class=nav-item > <a class=nav-link  href="/guide/">Guide</a> <li class=nav-item > <a class=nav-link  href="/contribute/">Contribute</a> <li class=nav-item > <a class=nav-link  href="/blog/">Blog</a> <li class=nav-item > <a class=nav-link  href="https://JuliaReinforcementLearning.github.io/ReinforcementLearning.jl/latest/">Doc</a> <li class=nav-item > <a class=nav-link  href="https://github.com/JuliaReinforcementLearning">Github</a> </ul> </div> </nav> <d-title><h1>Call for Contributions</h1><p>Reinforcement learning has undergone tremendous progress in recent years. The growing number of algorithms begets the need for comprehensive tools and implementations. Thus we call for all kinds of contributions from the community, including bug reports, feature proposals and implementations of new algorithms or reinforcement learning environments. This page is used to track what we hope to be added in the next few years.</p> </d-title> <d-byline></d-byline> <d-article class=franklin-content ><h2 id=environments ><a href="#environments" class=header-anchor >Environments</a></h2> <p>Many reinforcement learning environments in the Python world are not available in Julia yet. Though we can leverage <a href="https://github.com/JuliaPy/PyCall.jl">PyCall.jl</a> to interact with them, the overheads usually make this approach unacceptable. Following are some experiments we&#39;d like to have, either by wrapping the underlying C/C&#43;&#43; libraries or rewriting in Julia from scratch.</p> <ul> <li><p><a href="https://github.com/bulletphysics/bullet3">bullet3</a>. There&#39;re some discussions about how to write a wrapper <a href="https://github.com/JuliaReinforcementLearning/ReinforcementLearningEnvironments.jl/issues/15">here</a>. ⭐⭐⭐</p> <li><p><a href="https://github.com/datamllab/rlcard">rlcard</a>. It is suggested to be rewritten in Julia.⭐</p> <li><p><a href="https://github.com/deepmind/boxoban-levels">boxoban-levels</a> and <a href="https://github.com/mpSchrader/gym-sokoban">mpSchrader/gym-sokoban</a>. ⭐</p> <li><p><a href="https://github.com/maximecb/gym-minigrid">gym-minigrid</a>. Need a great design and rewritten in Julia.⭐</p> <li><p><a href="https://github.com/openai/procgen">procgen</a>. Environments in Procgen are written in C. One key feature is that Procgen environments are randomized.⭐⭐</p> <li><p><a href="https://github.com/PettingZoo-Team/MAgent">MAgent</a>. ⭐⭐</p> </ul> <aside>Here ⭐ means the difficulty.</aside> <p>Beside writing environments, it would be great if a unified wrapper is also provided in <a href="https://github.com/JuliaReinforcementLearning/ReinforcementLearningEnvironments.jl">ReinforcementLearningEnvironments.jl</a>.</p> <h2 id=algorithms ><a href="#algorithms" class=header-anchor >Algorithms</a></h2> <p>Note that each algorithm is suggested to provide at least one reproducible experiment.</p> <h3 id=q-learning_related ><a href="#q-learning_related" class=header-anchor >Q-Learning Related</a></h3> <ul> <li><p>QRDQN<d-cite key=dabney2018distributional ></d-cite>.</p> <li><p>FQF<d-cite key=yang2019fully ></d-cite>. This is the new SOTA among distributional methods.</p> </ul> <h3 id=policy_gradient ><a href="#policy_gradient" class=header-anchor >Policy Gradient</a></h3> <ul> <li><p>Soft Actor-Critic<d-cite key=haarnoja2018soft ></d-cite></p> <li><p>Twin Delayed DDPG<d-cite key=dankwa2019twin ></d-cite></p> </ul> <h3 id=model_based ><a href="#model_based" class=header-anchor >Model Based</a></h3> <ul> <li><p>MuZero<d-cite key=schrittwieser2019mastering ></d-cite></p> </ul> <h3 id=counterfactual_regret ><a href="#counterfactual_regret" class=header-anchor >Counterfactual Regret</a></h3> <ul> <li><p>Counterfactual multi-agent policy gradients<d-cite key=foerster2018counterfactual ></d-cite></p> <li><p>Deep CFR<d-cite key=brown2019deep ></d-cite></p> </ul> <h3 id=monte_carlo_tree_search ><a href="#monte_carlo_tree_search" class=header-anchor >Monte Carlo Tree Search</a></h3> <h2 id=infrastructures ><a href="#infrastructures" class=header-anchor >Infrastructures</a></h2> <h3 id=visualization ><a href="#visualization" class=header-anchor >Visualization</a></h3> <ul> <li><p>Integration with <a href="https://github.com/waralex/Dashboards.jl">Dashboards.jl</a>.</p> <li><p>Create custom recipes in <a href="http://makie.juliaplots.org/">Maike.jl</a>.</p> </ul> <h3 id=distributed_computing ><a href="#distributed_computing" class=header-anchor >Distributed Computing</a></h3> <h3 id=other_backends ><a href="#other_backends" class=header-anchor >Other Backends</a></h3> <ul> <li><p><a href="https://github.com/FluxML/Torch.jl">Torch.jl</a></p> </ul> <div></div></d-article> <d-appendix> <h3>Corrections</h3> <p>If you see mistakes or want to suggest changes, please <a href="https://github.com/JuliaReinforcementLearning/JuliaReinforcementLearning.github.io/issues">create an issue</a> on the source repository.</p> <d-bibliography src="/contribute/bibliography.bib"></d-bibliography> </d-appendix> <div class="distill-site-nav distill-site-footer"> <div class=row > <div class=col-md-3 ></div> <div class=col-md-6 > <p>This website is built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> of the <a href="https://github.com/tlienart/DistillTemplate">DistillTemplate</a> (licensed under <a href="https://github.com/distillpub/template/blob/master/LICENSE">Apache License 2.0</a>) and <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a>. The <a href="https://github.com/JuliaReinforcementLearning/JuliaReinforcementLearning.github.io">source code</a> of this website is licensed under <a href="https://github.com/JuliaReinforcementLearning/JuliaReinforcementLearning.github.io/blob/master/LICENSE">MIT License</a>. The <a href="https://github.com/JuliaReinforcementLearning">JuliaReinforcementLearning</a> organization was first created by <a href="https://github.com/jbrea">Johanni Brea</a> and then co-maintained by <a href="https://github.com/findmyway">Jun Tian</a>. And we thank <a href="https://github.com/JuliaReinforcementLearning/ReinforcementLearning.jl#contributors-">all the contributors </a> .</p> </div> <div class=col-md-3 ></div> </div> </div>